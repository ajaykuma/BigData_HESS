#load data from hdfs
load data inpath 'mydata/mydata-local1/kv1.txt' overwrite into table tbl2;
or 
hdfs dfs -cp mydata/mydata-local1/kv1.txt /user/itv000966/ajmydb.db/tbl2;
or
hdfs dfs -mv mydata/mydata-local1/kv1.txt /user/itv000966/ajmydb.db/tbl2;
or
hdfs dfs -get mydata/mydata-local1/kv1.txt mydata-local1
hdfs dfs -put mydata-local1/kv1.txt /user/itv000966/ajmydb.db/tbl2;


#load data from local machine
load data inpath 'mydata/kv1.txt' overwrite into table tbl2;
load data inpath 'mydata/kv1.txt' into table tbl2;
load data inpath 'mydata/kv1.txt' into table tbl2;
load data inpath 'mydata/kv1.txt' into table tbl2;

#create table with complex data types
hive (ajmydb)> create table tbl1(id int, name string, phpreferences array<string>,loc map <string,string>)
             > row format delimited
             > fields terminated by ','
             > collection items terminated by ':'
             > map keys terminated by '$';

load data local inpath 'mydata-local1/hivef3.txt' overwrite into table tbl1;


hive (ajmydb)> select id,name,phpreferences from tbl1 where size(phpreferences) >= 3;
hive (ajmydb)> select id,name,phpreferences[1] as second_pref from tbl1 where size(phpreferences) >= 3;
hive (ajmydb)> select id, name, phpreferences, regexp_replace(phpreferences[0],'iphone','reach_customer') from tbl1;

select id, name, phpreferences, regexp_replace(phpreferences[0],'iphone','reach_customer'),
concat_ws(phpreferences[0],phpreferences[1],'@@') as code_name from tbl1;

select name, phpreferences, regexp_replace(phpreferences[0],'iphone','reach_customer') ,concat_ws(phpreferences[0],phpreferences[1],'@') from tbl1;
select name, phpreferences, regexp_replace(phpreferences[0],'iphone','reach_customer') ,concat_ws(phpreferences[0],name,'@') from tbl1;

hive (ajmydb)> select name, phpreferences, regexp_replace(phpreferences[0],'iphone','reach_customer') as POA ,
reverse(concat_ws(phpreferences[0],name,'@')) as code_cust from tbl1;

hive (ajmydb)> select name, phpreferences, regexp_replace(phpreferences[0],'iphone','reach_customer') 
as POA ,substr(reverse(concat_ws(phpreferences[0],name,'@')),3) as code_cust from tbl1;

#from spark
>>> y = spark.sql("use ajmydb")
>>> x = spark.sql("select name, phpreferences, regexp_replace(phpreferences[0],'iphone','reach_customer') as POA ,reverse(concat_ws(phpreferences[0],name,'@')) as code_cust from tbl1")
>>> x.show(4)

>>> y = spark.sql("use ajmydb")
>>> z = spark.sql('create table tbl4 as select * from tbl1')
>>> a = spark.sql('select * from tbl4 limit 5')


#from hive again
hive (ajmydb)> show tables;
hive (ajmydb)> !hdfs dfs -ls -R /user/itv000966/ajmydb.db;

#merging data of a table into multiple files
hive (ajmydb)> create table tbl5 as select * from tbl2;

hive (ajmydb)> !hdfs dfs -ls -R /user/itv000966/ajmydb.db/tbl2;

hive (ajmydb)>!hdfs dfs -ls -R /user/itv000966/ajmydb.db/tbl5;

#going for default compression
hive (ajmydb)> set hive.exec.compress.output=true;
mapreduce.output.fileoutputformat.compress=true;
hive (ajmydb)> create table tbl6 as select * from tbl2;

#going for specific compression
hive (ajmydb)> set hive.exec.compress.output=true;
set mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.GzipCodec;
create table tbl7 as select * from tbl2;

hive (ajmydb)> create table tbl8(id int,name string,phpref array<string>,loc map<string,string>,addr struct<city:string,street:int,country:string>) 
row format delimited
 fields terminated by ','
collection items terminated by ':' 
map keys terminated by '$' ;

load data local inpath 'mydata-local1/hivef5.txt' overwrite into table tbl8;

hive (ajmydb)> select explode(phpref) from tbl8;

hive > select * from tbl2 where id > 300 order by id desc;

create table tbl9(id int,name string) partitioned by (doj string);
hive (ajmydb)> load data local inpath 'mydata-local1/kv1.txt' overwrite into table tbl9 partition (doj="1stfeb");

hive (ajmydb)> load data local inpath 'mydata-local1/kv1.txt' overwrite into table tbl9 partition (doj="1stmar");

hive (ajmydb)> load data local inpath 'mydata-local1/kv1.txt' into table tbl9 partition (doj="1stmar");

Time taken: 0.885 seconds
hive (ajmydb)> load data local inpath 'mydata-local1/kv1.txt' into table tbl9 partition (doj="1stmar");

hive (ajmydb)> select * from tbl9 where doj='1stjan';





















